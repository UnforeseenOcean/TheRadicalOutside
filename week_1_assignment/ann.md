#H1 [Do Artifacts Have Politics?](https://transitiontech.ca/pdf/Winner-Do-Artifacts-Have-Politics-1980.pdf)
Artifacts absolutely have politics. There are a million examples of how technology reinforces gender stereotypes/norms.  Everything from Siri/Alexa and other voice assistants being apparently female, to the history+design of birth control, to [VR hardware](https://www.theverge.com/2016/1/11/10749932/vr-hardware-needs-to-fit-women-too), to the [design of cockpits](http://www.nyu.edu/projects/nissenbaum/papers/manufacturing_gender.pdf) and car safety features.  (Journalist Rose Eveleth writes about bias often, [link to a few here](https://motherboard.vice.com/en_us/topic/design-bias).)

More recent examples include bias in algorithms that discriminate against women and minorities in hiring, school admission, criminal sentencing, and bank credit.  This form of ‘digital redlining’ serves to reinforce existing social structures and biases that favor white men.  As Winner states, "What we see here instead is an ongoing social process in which scientific knowledge, technological invention, and corporate profit reinforce each other in deeply entrenched patterns that bear the unmistakable stamp of political and economic power.”

I’m less convinced by the second reading of political artifacts.  As Winner states towards the end of his article, this reading requires that we agree on a common moral plane from which to judge whether or not technologies are “good” or “right.”  For example, Winner claims that the atom bomb must “be controlled by a centralized, rigidly hierarchical chain of command closed to all influences that might make its workings unpredictable. The internal social system of the bomb must be authoritarian; there is no other way.”  However, I think this is a failure of imagination.  

First, we must agree what constitutes “unpredictable.”  Next, we need to decide whether an extremely unlikely but catastrophic failure is better or worse than a more likely but less catastrophic failure.  For example, if in the rigidly hierarchical chain 99.9% of the time the bomb was inert/safe but .1% of the time a unstable individual used the bomb, is this inherently better than a distributed system where agreement from all citizens around the world (for example) was required in order to use the bomb?  What might that senario look like?  Would we, collectively, be less likely to use the bomb against major population centers, but more likely to deploy the bomb overall?  

In any case, as we are examining technologies through the lens of our current capitalist society it is difficult to imagine another system (collectivist, distributed, etc.).  I don’t think this means that the technologies that exist today could only exist in our current system, but rather we have yet to see them exist in any other system so we are hobbled by our failure of imagination, not by any inherent political leanings of the technologies themselves. 

Quotes I like:

- "Scarcely a new invention comes along that someone does not proclaim it the salvation of a free society."
- “But the corrective has its own shortcomings; taken literally, it suggests that technical things do not matter at all.” (The corrective being looking at the systems that create technologies, and within which technologies exist without looking at the objects themselves.)
- “Technological change expresses a panoply of human motives, not the least of which is the desire of some to have dominion over others, even though it may require an occasional sacrifice of cost-cutting and some violence to the norm of getting more from less.”
- "What we see here instead is an ongoing social process in which scientific knowledge, technological invention, and corporate profit reinforce each other in deeply entrenched patterns that bear the unmistakable stamp of political and economic power.”
- “In that sense technological innovations are similar to legislative acts or political foundings that establish a framework for public order that will endure over many generations.”
- “The issue here does not concern how many jobs will be created, how much income generated, how many pollutants added, or how many cancers produced. Rather, the issue has to do with ways in which choices about technology have important consequences for the form and quality of human associations.” → if technologies necessitate certain political systems, or are more likely to thrive under certain systems.
- “Taking the most obvious example, the atom bomb is an inherently political artifact. As long as it exists at all, its lethal properties demand that it be controlled by a centralized, rigidly hierarchical chain of command closed to all influences that might make its workings unpredictable. The internal social system of the bomb must be authoritarian; there is no other way.”  I think this is a failure of imagination.
- “In many instances, to say that some technologies are inherently political is to say that certain widely accepted reasons of practical necessity, especially the need to maintain crucial technological systems as smoothly working entities have tended to eclipse other sorts of moral and political reasoning.”
